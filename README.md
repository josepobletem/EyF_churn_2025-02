# ğŸ§  EyF Churn 2025 â€” Full ML Pipeline

Pipeline completo de modelado de churn con **LightGBM**, **Optuna** y **mÃ©trica de negocio personalizada**, inspirado en el enfoque de la **competencia EyF (UBA)**.

---

## ğŸ“‚ Estructura del Proyecto

```
EyF_churn_2025-02/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # datos crudos originales
â”‚   â”œâ”€â”€ processed/          # datos limpios + target + features finales combinadas
â”‚   â”œâ”€â”€ features/           # (opcional) dumps intermedios de features
â”‚   â”œâ”€â”€ test/               # datos de holdout / scoring (mes test_month)
â”‚   â””â”€â”€ README_data.md      # (opcional) descripciÃ³n de datasets
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model.pkl          # modelo candidato encontrado por optimizer
â”‚   â”œâ”€â”€ best_params.yaml        # hiperparÃ¡metros Ã³ptimos + metadata
â”‚   â”œâ”€â”€ final_model.pkl         # modelo final reentrenado en train_months
â”‚   â””â”€â”€ final_metrics.yaml      # mÃ©tricas in-sample finales
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ 01_base_tables.sql
â”‚   â”œâ”€â”€ 02_feat_numeric.sql
â”‚   â”œâ”€â”€ 03_final_join.sql
â”‚   â”œâ”€â”€ 04_risk_behavior_and_join.sql
â”‚   â””â”€â”€ 05_behavioral_features.sql
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_prep.py            # genera dataset procesado con target
â”‚   â”œâ”€â”€ feature_engineering.py  # arma features en DuckDB/SQL
â”‚   â”œâ”€â”€ optimizer.py            # Optuna + LightGBM + gan_eval
â”‚   â”œâ”€â”€ trainer.py              # reentrena modelo final con best_params.yaml
â”‚   â”œâ”€â”€ predict.py              # predice modelo entrenado con best_params.yaml
â”‚   â”œâ”€â”€ trainer_ensemble_and_predict_gcp.py
â”‚   â”œâ”€â”€ trainer_ensemble_and_predict.py
â”‚   â””â”€â”€ trainer_zlgbm_canaritos.py   
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data_prep.py           # prueba carga y procesamiento inicial
â”‚   â”œâ”€â”€ test_feature_engineering.py # prueba consultas SQL y features generadas
â”‚   â”œâ”€â”€ test_optimizer.py           # prueba bÃºsqueda de hiperparÃ¡metros
â”‚   â”œâ”€â”€ test_trainer.py             # prueba entrenamiento final y guardado de modelo
â”‚   â””â”€â”€ conftest.py (opcional)      # configuraciÃ³n comÃºn de pytest (fixtures)
â”œâ”€â”€ run_full_pipeline.bat
â”œâ”€â”€ run_full_pipeline.sh
â”œâ”€â”€ README.md
â”œâ”€â”€ Makefile
â””â”€â”€ requirements.txt

```

---

## ğŸš€ DescripciÃ³n del Pipeline

El pipeline consta de **4 etapas principales** ejecutadas secuencialmente:

### **1ï¸âƒ£ Data Preparation (`src/data_prep.py`)**
- Limpieza, selecciÃ³n y formateo del dataset base (`competencia_01.csv`).
- GeneraciÃ³n de columna target `clase_ternaria` y sus variantes binarias.
- Exporta dataset procesado:  
  `data/processed/competencia_01.csv`

### **2ï¸âƒ£ Feature Engineering (`src/feature_engineering.py`)**
- Usa **DuckDB** y **SQL modular** (`sql/*.sql`) para construir features.
- Ejecuta pasos automÃ¡ticos:
  - `01_base_tables.sql`
  - `02_feat_numeric.sql`
  - `03_final_join.sql`
- Genera dataset final:
  `data/processed/competencia_01_features.csv`

ğŸ’¡ Si el script lanza un error tipo:
```
FileNotFoundError: No se encontrÃ³ el archivo SQL sql/03_final_join.sql
```
â†’ asegurate de crear ese archivo SQL con la uniÃ³n final de features.

---

### **3ï¸âƒ£ Optuna + LightGBM (`src/optimizer.py`)**

Busca los **mejores hiperparÃ¡metros** mediante **Optuna**, optimizando una mÃ©trica de negocio propia (`gan_eval`).

#### ğŸ”¹ LÃ³gica de particiÃ³n:
```python
mes_train = [202101, 202102, 202103]
mes_test = 202104
```

#### ğŸ”¹ MÃ©trica de negocio:
```python
ganancia_acierto = 780000
costo_estimulo = 20000

def lgb_gan_eval(y_pred, data):
    weight = data.get_weight()
    ganancia = np.where(weight == 1.00002, ganancia_acierto, 0)              - np.where(weight < 1.00002, costo_estimulo, 0)
    ganancia = np.cumsum(ganancia[np.argsort(y_pred)[::-1]])
    return 'gan_eval', np.max(ganancia), True
```

#### ğŸ”¹ Espacio de bÃºsqueda (Optuna):
Explora un rango amplio de parÃ¡metros:

```python
params = {
    "learning_rate": trial.suggest_float(5e-4, 0.2, log=True),
    "num_leaves": trial.suggest_int(16, 512),
    "max_depth": trial.suggest_int(-1, 16),
    "min_data_in_leaf": trial.suggest_int(5, 2000),
    "feature_fraction": trial.suggest_float(0.4, 1.0),
    "bagging_fraction": trial.suggest_float(0.5, 1.0),
    "bagging_freq": trial.suggest_int(0, 10),
    "min_split_gain": trial.suggest_float(0.0, 1.0),
    "lambda_l1": trial.suggest_float(1e-8, 10.0, log=True),
    "lambda_l2": trial.suggest_float(1e-8, 10.0, log=True),
    "scale_pos_weight": trial.suggest_float(0.5, 10.0, log=True),
}
```

#### ğŸ”¹ EvaluaciÃ³n en CV:
- `nfold = 5`  
- `num_boost_round = 5000`  
- `early_stopping_rounds = 200`

LightGBM imprime algo como:
```
[500] valid's gan_eval: 1.7424e+08 + 1.09826e+07
```
ğŸ‘‰ Promedio Â± desviaciÃ³n entre los 5 folds.

---

### **4ï¸âƒ£ Entrenamiento final (`src/trainer.py`)**
- Usa los **mejores hiperparÃ¡metros** encontrados por Optuna.
- Reentrena con todos los datos de entrenamiento.
- Guarda:
  - `models/best_model.pkl`
  - `models/best_params.yaml`

---

## âš™ï¸ EjecuciÃ³n del Pipeline

### ğŸ”¸ En Windows
```bash
run_full_pipeline.bat
```

### ğŸ”¸ En Linux / WSL
```bash
bash run_full_pipeline.sh
```

Ambos scripts hacen:
1. Activan el entorno `.venv`.
2. Ejecutan:
   - `python -m src.data_prep`
   - `python -m src.feature_engineering`
   - `python -m src.optimizer`
   - `python -m src.trainer`

---

## ğŸ§© ConfiguraciÃ³n (`config/config.yaml`)

Ejemplo de configuraciÃ³n mÃ­nima:

```yaml
paths:
  # dataset crudo original (sin target todavÃ­a)
  #raw_dataset: "data/raw/competencia_01_crudo.csv"
  raw_dataset: "data/raw/competencia_02_crudo.csv"

  # dataset con target churn/class (output de data_prep.py)
  #processed_dataset: "data/processed/competencia_01.csv"
  #processed_dataset: "data/processed/competencia_02.csv"
  processed_dataset: "gs://jose_poblete_bukito3/eyf/processed/competencia_02.parquet"

  # dataset final con features listo para entrenar (output de feature_engineering.py)
  #feature_dataset: "data/processed/competencia_01_features_new.csv"
  #feature_dataset: "data/processed/competencia_02_features_new.parquet"
  feature_dataset:   "gs://jose_poblete_bukito3/eyf/features/competencia_02_features_new.parquet"
columns:
  # identificador Ãºnico del cliente
  id_column: "numero_de_cliente"

  # periodo tipo YYYYMM (por ejemplo 202104)
  period_column: "foto_mes"

  # target creado en data_prep.py: BAJA+1 / BAJA+2 / CONTINUA
  target_column: "clase_ternaria"
  
  # target para el optimizador
  binary_target_col: "clase_binaria2"
  peso_col: "clase_peso"
  binary_target_gan: "clase_binaria1"

logic:
  # DocumentaciÃ³n de negocio de churn
  churn_definition: |
    CASE
      WHEN esta_t1 = 0 THEN 'BAJA+1'
      WHEN esta_t1 = 1 AND esta_t2 = 0 THEN 'BAJA+2'
      ELSE 'CONTINUA'
    END
  time_granularity: "mes"

features:
  # nombre con el que vamos a registrar el dataset base en DuckDB
  # (es el processed_dataset leÃ­do por Python)
  base_table_name: "base_clientes"

  # orden de ejecuciÃ³n de los SQL
  steps:
    - "sql/01_base_tables.sql"
    - "sql/02_feat_numeric.sql"
    - "sql/03_final_model.sql"
    - "sql/04_risk_behavior_and_join.sql"
    - "sql/05_behavioral_features.sql"

train:
  # ya los tenÃ­as (pueden quedar aunque no se usen aquÃ­)
  n_models: 5
  seed: 12345
  seeds: [464939, 782911, 213713, 811157, 502717, 203, 307, 409, 503, 607, 701, 809, 907, 1009,
          1103, 1201, 1301, 1409, 1501, 1601, 1709, 1801, 1901, 2003,
          782911, 101, 213713]
  decision_threshold: 0.025

  # âš™ï¸ NUEVO PARA ESTE SCRIPT
  models_dir: "gs://jose_poblete_bukito3/eyf/zlgbm"  # donde se guardan modelo y Ã¡rboles
  kaggle_dir: "gs://jose_poblete_bukito3/eyf/kaggle" # donde se guardan archivos Kaggle

  train_months: [ #201905, 201906,
                 201907,
                 201908, 
                 201909, 
                 201910,
                 201911, 
                 201912,
                 202001,
                 #202002, 202003,
                 202004, 
                 202005, 
                 202006,
                 202007,
                 202008, 
                 202009, 202010, 202011, 202012,
                 202101, 
                 202102,
                 202103,
                 202104,
                 202105,
                 202106]

  future_months: [202108]   # como pide la consigna

  qcanaritos: 5                   # cantidad de canaritos
  experimento: "zlgbm_canarios_v1"  # sufijo para nombre KA...
  top_n_kaggle: 11500               # cantidad de envÃ­os = 1

```

---

## ğŸ“Š MÃ©tricas y Logs

Los resultados de CV se muestran en consola, por ejemplo:

```
[1000] valid's gan_eval: 1.80624e+08 + 1.04733e+07
[1500] valid's gan_eval: 1.84200e+08 + 7.59254e+06
CV OK. Mejor gan_eval(mean)=184.2M Â± 7.6M en iter=1500
```

Los artefactos se guardan en:
- `models/best_model.pkl`
- `models/best_params.yaml`

---

## ğŸ§  InterpretaciÃ³n de la MÃ©trica `gan_eval`

| Valor | Significado |
|--------|--------------|
| `1.842e+08` | Ganancia promedio (media entre folds) |
| `Â± 7.592e+06` | Variabilidad entre folds |
| Intervalo estimado | [176M, 192M] |
| Variabilidad relativa | ~4.1% â†’ modelo estable |

---

## ğŸ› ï¸ Dependencias Principales

| LibrerÃ­a | Uso |
|-----------|------|
| `pandas` | ManipulaciÃ³n de datos |
| `numpy` | CÃ¡lculos numÃ©ricos |
| `lightgbm` | Modelo de boosting |
| `optuna` | OptimizaciÃ³n bayesiana |
| `duckdb` | Feature engineering con SQL |
| `pyyaml` | ConfiguraciÃ³n |
| `pydantic` | ValidaciÃ³n de config |
| `logging` | Trazabilidad de pipeline |

---

## ğŸ’¾ Resultados esperados

Al finalizar, el pipeline genera:
- Dataset enriquecido (`data/processed/competencia_01_features.csv`)
- Modelo LightGBM ajustado a la mÃ©trica de negocio (`models/best_model.pkl`)
- ParÃ¡metros Ã³ptimos (`models/best_params.yaml`)
- Logs detallados en salida estÃ¡ndar.

---

## ğŸ‘¤ Autor

**JosÃ© Poblete M.**  
Data Scientist & MLOps Engineer  
Facultad de Ciencias Naturales â€” UBA.
